---
title: "p8105_hw5_ml5363"
author: "Muxin Li"
date: "2025-11-09"
output: github_document
---

```{r}
library(tidyverse)
library(broom)
library(purrr)

```

## Problem 1
```{r}
bdays_df=function(n_room){
  bdays=sample(1:365,n_room,replace = TRUE)
  repeat_bdays=length(unique(bdays))< n_room
  repeat_bdays
}
```

```{r}
bdays_sim=
  expand_grid(
    bdays=2:50,
    iter=1:10000
  )|>
  mutate(result=map_lgl(bdays,bdays_df))|>
  group_by(bdays)|>
  summarise(
    pro_bday=mean(result)
  )
  
  
```

```{r}
bdays_sim|>
  ggplot(aes(x=bdays,y=pro_bday))+
  geom_point()+
  geom_line()
```
comment:
The probability that at least two people share a birthday increases rapidly as the group size grows. When the group size reaches around 23 people, the probability exceeds 50%, meaning it is more likely than not that two people will share a birthday. By the time the group size reaches 50, the probability is nearly 1.

## Problem 2
```{r}
sim_mean=function(mean){
  x=rnorm(30,mean,5)
  t_result=t.test(x,mu=0)
  tidy(t_result)
}
output=vector("list",5000)
for (i in 1:5000) {
  output[[i]]=sim_mean(0)
}
sim_result=bind_rows(output)
sim_result|>
  select(estimate,p.value)
```

for mean=1,2,3,4,5,6
```{r}
mean_df=function(mean){
  output=vector("list",5000)
  for (i in 1:5000) {
    output[[i]]=sim_mean(mean)
  }
  sim_result=bind_rows(output)
  sim_result|>
    select(estimate,p.value)
}

mean_sim_df=function(mean){
  mean_df(mean)|>
  filter(p.value<0.05)|>
  mutate(mean_value=mean)|>
  mutate(prop=n()/5000)|>
  distinct(mean_value,prop)
}

output=vector("list",7)
for (i in 1:7) {
  output[[i]]=mean_sim_df(i-1)
}
mean_sim_result= bind_rows(output)

ggplot(mean_sim_result,aes(x=mean_value,y=prop))+
  geom_point()+
  geom_line()+
  geom_text(aes(label = sprintf("%.4f", prop), vjust = -1)) +
  scale_x_continuous(breaks = 0:6, labels = 0:6, minor_breaks = NULL)
```
comment:
There is a positive association between effect size (x-axis, mean_value) and statistical power (y-axis, proportion).
As the effect size increases, the power also increases — at first gradually, then more steeply — until it reaches close to 1.0, where it plateaus

```{r}
mean_sim_df2=function(mean){
  mean_df(mean)|>
  filter(p.value<0.05)|>
  summarize(mean_value=mean, mean_estimate=mean(estimate))
}

output2=vector("list",7)
for (i in 1:7) {
  output2[[i]]=mean_sim_df2(i-1)
}
mean_sim_result2= bind_rows(output2)
ggplot(mean_sim_result2,aes(x=mean_value,y=mean_estimate))+
  geom_point()+
  geom_line()+
  geom_text(aes(label = sprintf("%.4f", mean_estimate), vjust = -1)) +
  scale_x_continuous(breaks = 0:6, labels = 0:6, minor_breaks = NULL)
  
```
comment:
Across all samples,$\hat{\mu}$ is an unbiased estimator of $\mu$, so the average estimate is close to the true mean (as plot shows)

## Problem 3
```{r}
url = "https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv"
homicides=read_csv(url)
```
comment:
The dataset is a tibble containing 52,179 rows and 12 columns, representing homicide records compiled by The Washington Post from police departments across the United States.

```{r}
homicides_city=
  homicides|>
  mutate(city_state=paste(city,state,sep = ","))


homicides_city|>
  drop_na(disposition)|>
  group_by(city,disposition)|>
  summarise(n=n())|>
  pivot_wider(
    names_from = disposition,
    values_from = n,
    values_fill = 0
  )|>
  mutate(total_homicides=`Closed by arrest` + `Closed without arrest` + `Open/No arrest`)|>
  mutate(unsolved_homicides=`Closed without arrest` + `Open/No arrest`)|>
  select(city,total_homicides,unsolved_homicides)
```

```{r}
homicides_city|>
  drop_na(disposition)|>
  filter(city_state=="Baltimore,MD")|>
  group_by(city_state,disposition)|>
  summarise(n=n())|>
  pivot_wider(
    names_from = disposition,
    values_from = n
  )|>
  mutate(total_homicides=`Closed by arrest` + `Closed without arrest` + `Open/No arrest`)|>
  mutate(unsolved_homicides=`Closed without arrest` + `Open/No arrest`)|>
  mutate(prop=unsolved_homicides/total_homicides)

Baltimore_MD =prop.test(1825,2827)

prop.test(1825,2827)|>
  tidy()|>
  select(estimate,conf.low, conf.high )

```

```{r}
source("prop_test.R")



city_name_homicides=
  homicides_city|>
  distinct(city_state)


prop_test_all=
  expand_grid(
  city_name_homicides,
)|>
  mutate(
    city_prop=map(city_state,prop_test)
  )|>
  unnest(city_prop)
  
prop_test_all=select(prop_test_all,city_state, prop, estimate,conf.low, conf.high)

prop_test_all
```

```{r}
prop_test_all=
  prop_test_all|>
  arrange(prop)|>
  mutate(city_state = factor(city_state, levels = city_state))

ggplot(prop_test_all, aes(x = city_state, y = estimate)) +
  geom_point(color = "red", size = 2) +  
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.3) +
  coord_flip() +                            
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City",
    y = "Estimated Proportion (with 95% CI)"
  ) +
  theme_minimal(base_size = 12)
```

